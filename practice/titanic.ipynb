{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Embarked  Survived\n",
      "1         1  0.553571\n",
      "2         2  0.389610\n",
      "0         0  0.339009\n",
      "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  FamilySize  IsAlone\n",
      "0         0       3    0    1     0         0      1           2        0\n",
      "1         1       1    1    2     3         1      3           2        0\n",
      "2         1       3    1    1     1         0      2           1        1\n",
      "3         1       1    1    2     3         0      3           2        0\n",
      "4         0       3    0    2     1         0      1           1        1\n",
      "5         0       3    0    1     1         2      1           1        1\n",
      "6         0       1    0    3     3         0      1           1        1\n",
      "7         0       3    0    0     2         0      4           5        0\n",
      "8         1       3    1    1     1         0      3           3        0\n",
      "9         1       2    1    0     2         1      3           2        0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((891, 8), (418, 8), (891,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#reading data\n",
    "traindata = pd.read_csv('all/train.csv')\n",
    "testdata = pd.read_csv('all/test.csv')\n",
    "\n",
    "traindata = traindata.drop(['Ticket','Cabin'],axis=1)\n",
    "testdata = testdata.drop(['Ticket','Cabin'], axis=1)\n",
    "combine = [traindata,testdata]\n",
    "\n",
    "mapper = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5}\n",
    "for data in combine:\n",
    "    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    data['Title'] = data['Title'].replace(['Lady','Capt','Col','Countess','Don','Jonkheer',\\\n",
    "                                          'Major','Rev','Sir','Dr','Dona'],'Rare')\n",
    "    data['Title'] = data['Title'].replace(['Mlle','Mme','Ms'],'Miss')\n",
    "    data['Title'] = data['Title'].map(mapper).fillna(0)\n",
    "    data['Sex'] = data['Sex'].map({'female':1, 'male':0}).astype(int)\n",
    "\n",
    "# print(pd.crosstab(traindata['Title'],traindata['Sex']))\n",
    "\n",
    "# print(traindata[['Title','Survived']].groupby('Title').mean())\n",
    "\n",
    "\n",
    "traindata=traindata.drop(['Name', 'PassengerId'], axis=1)\n",
    "testdata=testdata.drop(['Name'], axis=1)\n",
    "combine = [traindata, testdata]\n",
    "\n",
    "guess_age = np.zeros((2,3))\n",
    "for data in combine:\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            guess_data = data[(data['Sex']==i) & (data['Pclass']==j+1)]['Age'].dropna()\n",
    "            age = guess_data.median()\n",
    "            guess_age[i, j] = int(2*age+1)*0.5\n",
    "            \n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            data.loc[(data['Sex']==i) & (data['Pclass']==j+1) & (data.Age.isnull()),\\\n",
    "                     'Age'] = guess_age[i,j]\n",
    "    data['Age']=data['Age'].astype(int)\n",
    "\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']=4\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    freq_port = dataset.Embarked.dropna().mode()[0]\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    dataset['Fare'].fillna(testdata['Fare'].dropna().median(), inplace=True)\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    \n",
    "traindata=traindata.drop(['SibSp', 'Parch'], axis=1)\n",
    "testdata=testdata.drop(['SibSp', 'Parch'], axis=1)\n",
    "print(traindata[['Embarked', 'Survived']].groupby(['Embarked'],\\\n",
    "                                                  as_index=False).mean().sort_values(by='Survived', \\\n",
    "                                                                                     ascending=False))\n",
    "print(traindata.head(10))\n",
    "\n",
    "Y_train = traindata['Survived']\n",
    "X_train = traindata.drop('Survived', axis=1)\n",
    "X_test = testdata.drop('PassengerId',axis=1).copy()\n",
    "X_train.shape, X_test.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.59\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver=\"lbfgs\")\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train,Y_train)*100,2)\n",
    "coeff_df = pd.DataFrame(traindata.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)\n",
    "print(acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Successfully submitted to Titanic: Machine Learning from Disaster'\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": testdata[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "import subprocess\n",
    "#subprocess.check_output(['ls','-l']) #all that is technically needed...\n",
    "print(subprocess.check_output(['kaggle','competitions','submit', '-c', \\\n",
    "                               'titanic', '-f', 'submission.csv', '-m', '\"Message\"']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.54"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=1, kernel=\"poly\", gamma=\"auto\", degree=6)\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krullun/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krullun/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.55"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>88.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>88.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>85.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>83.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>81.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>79.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>79.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "3               Random Forest  88.55\n",
       "7               Decision Tree  88.55\n",
       "1                         KNN  85.75\n",
       "0     Support Vector Machines  83.39\n",
       "2         Logistic Regression  81.26\n",
       "5                  Perceptron  80.25\n",
       "4                 Naive Bayes  79.91\n",
       "6  Stochastic Gradient Decent  79.57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(traindata, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=50)\n",
    "\n",
    "# grid = sns.FacetGrid(traindata, col='Survived', row='Pclass')#, size=2.2, aspect=1.6)\n",
    "# grid.map(plt.hist, 'Age', alpha=.5, bins=10)\n",
    "# grid.add_legend();\n",
    "\n",
    "# grid = sns.FacetGrid(train_df, col='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = ('https://archive.ics.uci.edu/ml/' 'machine-learning-databases/abalone/abalone.data')\n",
    "cols = ['sex', 'length', 'diam', 'height', 'weight', 'rings']\n",
    "abalone = pd.read_csv(url, usecols=[0, 1, 2, 3, 4, 8], names=cols)\n",
    "print(abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.util.testing as tm\n",
    "tm.N, tm.K = 4,6\n",
    "np.random.seed(444)\n",
    "# tm.makeTimeDataFrame(freq='m').head()\n",
    "# print(pd.Series._accessors)\n",
    "pd.Series._accessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "datecols = ['year', 'month', 'day']\n",
    "\n",
    "df = pd.DataFrame(list(product([2017, 2016], [1, 2], [1, 2, 3])),\n",
    "                  columns=datecols)\n",
    "df['data'] = np.random.randn(len(df))\n",
    "# print(df)\n",
    "df.index = pd.to_datetime(df[datecols])\n",
    "# print(df)\n",
    "a = pd.Series(df.index)\n",
    "print(a.dt.weekday_name)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr = pd.Series([\n",
    "    'Washington, D.C. 20003',\n",
    "    'Brooklyn, NY 11211-1755',\n",
    "    'Omaha, NE 68154',\n",
    "    'Pittsburgh, PA 15211'\n",
    "])\n",
    "\n",
    "print(addr.str.upper())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(addr.str.count(r'\\d'))  # 5 or 9-digit zip?\n",
    "\n",
    "regex = (r'(?P<city>[A-Za-z ]+), '      # One or more letters\n",
    "         r'(?P<state>[A-Z]{2}) '        # 2 capital letters\n",
    "         r'(?P<zip>\\d{5})(?:-\\d{4})?')  # Optional 4-digit extension\n",
    "\n",
    "addr.str.replace('.', '').str.extract(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = pd.Series([\n",
    "    'periwinkle',\n",
    "    'mint green',\n",
    "    'burnt orange',\n",
    "    'periwinkle',\n",
    "    'burnt orange',\n",
    "    'rose',\n",
    "    'rose',\n",
    "    'mint green',\n",
    "    'rose',\n",
    "    'navy'\n",
    "])\n",
    "\n",
    "mapper = {a: b for b, a in enumerate(colors.unique())}\n",
    "as_int = colors.map(mapper)\n",
    "print(as_int)\n",
    "cc = colors.astype('category')\n",
    "# cc.cat.categories\n",
    "cc.cat.reorder_categories(mapper).cat.codes\n",
    "cc = cc.cat.add_categories(['alpha'])\n",
    "cc.iloc[5] = 'alpha'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
